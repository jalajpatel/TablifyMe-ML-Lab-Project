{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from PIL import Image\nfrom transformers import DetrImageProcessor\nfrom transformers import TableTransformerForObjectDetection\n\nimport torch\nimport matplotlib.pyplot as plt\nimport os\nimport psutil\nimport time\nfrom transformers import DetrFeatureExtractor\nfeature_extractor = DetrFeatureExtractor()\nimport pandas as pd\n\n!pip -q install pytesseract pillow pandas\nimport pytesseract\n\nmodel = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-detection\")","metadata":{"id":"LOX1__3nrezW","outputId":"92369b25-1674-4336-d5a1-9f7339918980","execution":{"iopub.status.busy":"2023-11-08T18:29:45.406091Z","iopub.execute_input":"2023-11-08T18:29:45.406526Z","iopub.status.idle":"2023-11-08T18:29:55.624139Z","shell.execute_reply.started":"2023-11-08T18:29:45.406494Z","shell.execute_reply":"2023-11-08T18:29:55.622590Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at microsoft/table-transformer-detection were not used when initializing TableTransformerForObjectDetection: ['model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked']\n- This IS expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]\n\ndef plot_results(pil_img, scores, labels, boxes):\n    plt.figure(figsize=(16,10))\n    plt.imshow(pil_img)\n    ax = plt.gca()\n    colors = COLORS * 100\n    for score, label, (xmin, ymin, xmax, ymax),c  in zip(scores.tolist(), labels.tolist(), boxes.tolist(), colors):\n        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n                                   fill=False, color=c, linewidth=3))\n        text = f'{model.config.id2label[label]}: {score:0.2f}'\n        ax.text(xmin, ymin, text, fontsize=15,\n                bbox=dict(facecolor='yellow', alpha=0.5))\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-08T18:29:55.626404Z","iopub.execute_input":"2023-11-08T18:29:55.627281Z","iopub.status.idle":"2023-11-08T18:29:55.635904Z","shell.execute_reply.started":"2023-11-08T18:29:55.627251Z","shell.execute_reply":"2023-11-08T18:29:55.634464Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def table_detection(file_path):\n    image = Image.open(file_path).convert(\"RGB\")\n    width, height = image.size\n    image.resize((int(width*0.5), int(height*0.5)))\n    \n    feature_extractor = DetrImageProcessor()\n    encoding = feature_extractor(image, return_tensors=\"pt\")\n\n    with torch.no_grad():\n        outputs = model(**encoding)\n\n    width, height = image.size\n    results = feature_extractor.post_process_object_detection(outputs, threshold=0.7, target_sizes=[(height, width)])[0]\n    plot_results(image, results['scores'], results['labels'], results['boxes'])\n    return results['boxes']","metadata":{"id":"uuvc_hZ7PTEj","outputId":"1d67020e-9840-41de-e9bc-cd48dd7f3c1c","execution":{"iopub.status.busy":"2023-11-08T18:29:55.637196Z","iopub.execute_input":"2023-11-08T18:29:55.637549Z","iopub.status.idle":"2023-11-08T18:29:55.654723Z","shell.execute_reply.started":"2023-11-08T18:29:55.637518Z","shell.execute_reply":"2023-11-08T18:29:55.653935Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"ram_usage = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024\n\nprint(f\"ram usage : {ram_usage}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-08T18:29:55.656618Z","iopub.execute_input":"2023-11-08T18:29:55.657434Z","iopub.status.idle":"2023-11-08T18:29:55.678508Z","shell.execute_reply.started":"2023-11-08T18:29:55.657395Z","shell.execute_reply":"2023-11-08T18:29:55.677141Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"ram usage : 1158.40625\n","output_type":"stream"}]},{"cell_type":"code","source":"count = 0\nroot = \"/kaggle/input/pubtables-img-detect-test/PubTables-1M-Detection_Images_Test\"\n\nfor file in os.listdir(root):\n    file_path = os.path.join(root, file)\n    start_time = time.time()\n    \n    pred_bbox = table_detection(file_path)\n    \n    \n    count += 1\n    \n    end_time = time.time()\n    time_usage = end_time - start_time\n    ram_usage = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024\n    \n    print(f\"Iteration {count + 1} - RAM Usage: {ram_usage:.2f} MB, Time Usage: {time_usage:.2f} seconds\")\n\n    if count > 2:\n        break\n","metadata":{"execution":{"iopub.status.busy":"2023-11-08T18:29:55.680091Z","iopub.execute_input":"2023-11-08T18:29:55.681654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Table structure recognition\n\nTable structure recognition is the task of identifying the several rows, columns, cells in a table.\n\nLet's load a demo table (which I took from the [paper](https://openaccess.thecvf.com/content/CVPR2022/html/Smock_PubTables-1M_Towards_Comprehensive_Table_Extraction_From_Unstructured_Documents_CVPR_2022_paper.html)) and see how our model does.","metadata":{"id":"TCt6h9UCOQH6"}},{"cell_type":"code","source":"file = '/kaggle/input/pubtables-subset-100k/subset/img_test/PMC1064078_table_0.jpg'\nimage = Image.open(file).convert(\"RGB\")\nimage","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nfrom PIL import Image","metadata":{"id":"hu0r5mRW957s","outputId":"942ae0a8-f9f6-47d1-f3b0-b53ed3ae5108","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TableTransformerForObjectDetection\n\nmodel = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-structure-recognition\")","metadata":{"id":"vF6TFoNcOwyY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef cell_detection(file_path):\n\n    image = Image.open(file_path).convert(\"RGB\")\n    width, height = image.size\n    image.resize((int(width*0.5), int(height*0.5)))\n\n\n    encoding = feature_extractor(image, return_tensors=\"pt\")\n    encoding.keys()\n\n    with torch.no_grad():\n      outputs = model(**encoding)\n\n\n    target_sizes = [image.size[::-1]]\n    results = feature_extractor.post_process_object_detection(outputs, threshold=0.6, target_sizes=target_sizes)[0]\n    plot_results(image, results['scores'], results['labels'], results['boxes'])\n    model.config.id2label","metadata":{"id":"NKpkdMtvPeZc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ram_usage = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024\n\nprint(f\"ram usage : {ram_usage}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 0\nroot = \"/kaggle/input/pubtables-subset-100k/subset/img_test\"\nfor file in os.listdir(root):\n    file_path= os.path.join(root, file)\n    start_time = time.time()\n    \n    cell_detection(file_path)\n    count+=1\n    \n    end_time = time.time()\n    time_usage = end_time - start_time\n    ram_usage = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024\n    \n    print(f\"Iteration {count + 1} - RAM Usage: {ram_usage:.2f} MB, Time Usage: {time_usage:.2f} seconds\")\n    \n    if(count>2):\n        break\n    ","metadata":{"id":"B3XF8EzCNrio","outputId":"b4ed6be5-f9b8-44b7-8315-a6c319d1c62f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_results_specific(pil_img, scores, labels, boxes,lab):\n    plt.figure(figsize=(16, 10))\n    plt.imshow(pil_img)\n    ax = plt.gca()\n    colors = COLORS * 100\n    for score, label, (xmin, ymin, xmax, ymax), c in zip(scores.tolist(), labels.tolist(), boxes.tolist(), colors):\n        if label == lab:\n            ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n                                       fill=False, color=c, linewidth=3))\n            text = f'{model.config.id2label[label]}: {score:0.2f}'\n            ax.text(xmin, ymin, text, fontsize=15,\n                    bbox=dict(facecolor='yellow', alpha=0.5))\n    plt.axis('off')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_box_specific(image_path,labelnum):\n    image = Image.open(image_path).convert(\"RGB\")\n    width, height = image.size\n\n    encoding = feature_extractor(image, return_tensors=\"pt\")\n\n    with torch.no_grad():\n        outputs = model(**encoding)\n\n    results = feature_extractor.post_process_object_detection(outputs, threshold=0.7, target_sizes=[(height, width)])[0]\n    plot_results_specific(image, results['scores'], results['labels'], results['boxes'],labelnum)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_boxes(image_path):\n    image = Image.open(image_path).convert(\"RGB\")\n    width, height = image.size\n\n    encoding = feature_extractor(image, return_tensors=\"pt\")\n\n    with torch.no_grad():\n        outputs = model(**encoding)\n\n    results = feature_extractor.post_process_object_detection(outputs, threshold=0.7, target_sizes=[(height, width)])[0]\n    boxes = results['boxes'].tolist()\n    labels = results['labels'].tolist()\n\n    return boxes,labels","metadata":{"id":"KAA5ngwwPiJk","outputId":"838dfdb8-a31f-46f4-8a42-d1dc0d29cc70","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_table(image_path):\n    image = Image.open(image_path).convert(\"RGB\")\n    boxes,labels = compute_boxes(image_path)\n    \n    cell_locations = []\n\n    for box_row, label_row in zip(boxes, labels):\n        if label_row == 2:\n            for box_col, label_col in zip(boxes, labels):\n                if label_col == 1:\n                    cell_box = (box_col[0], box_row[1], box_col[2], box_row[3])\n                    cell_locations.append(cell_box)\n\n    cell_locations.sort(key=lambda x: (x[1], x[0]))\n    \n    num_columns = 0\n    box_old = cell_locations[0]\n\n    for box in cell_locations[1:]:\n        x1, y1, x2, y2 = box\n        x1_old, y1_old, x2_old, y2_old = box_old\n        num_columns += 1\n        if y1 > y1_old:\n            break\n        \n        box_old = box\n        \n    headers = []\n    for box in cell_locations[:num_columns]:\n        x1, y1, x2, y2 = box\n        cell_image = image.crop((x1, y1, x2, y2)) \n        new_width = cell_image.width * 4\n        new_height = cell_image.height * 4\n        cell_image = cell_image.resize((new_width, new_height), resample=Image.LANCZOS)\n        cell_text = pytesseract.image_to_string(cell_image)\n        headers.append(cell_text.rstrip()) \n\n    df = pd.DataFrame(columns=headers)\n\n    row = []\n    for box in cell_locations[num_columns:]:\n        x1, y1, x2, y2 = box\n        cell_image = image.crop((x1, y1, x2, y2)) \n        new_width = cell_image.width * 4\n        new_height = cell_image.height * 4\n        cell_image = cell_image.resize((new_width, new_height), resample=Image.LANCZOS)\n        cell_text = pytesseract.image_to_string(cell_image)\n\n        if len(cell_text) > num_columns:\n            cell_text = cell_text[:num_columns]\n\n        row.append(cell_text.rstrip())\n\n        if len(row) == num_columns:\n            df.loc[len(df)] = row\n            row = []\n            \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image_path = '/kaggle/input/pubtables-subset-100k/subset/img_test/PMC1112589_table_0.jpg'\nimage_path = '/kaggle/input/private/abc.png'\ndraw_box_specific(image_path,1)\ndf = extract_table(image_path)\ndf.to_csv('data.csv', index=False)","metadata":{"execution":{"iopub.status.idle":"2023-11-08T18:30:10.715153Z","shell.execute_reply.started":"2023-11-08T18:30:03.093656Z","shell.execute_reply":"2023-11-08T18:30:10.713166Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-11-08T18:30:10.716555Z","iopub.execute_input":"2023-11-08T18:30:10.716882Z","iopub.status.idle":"2023-11-08T18:30:10.728252Z","shell.execute_reply.started":"2023-11-08T18:30:10.716850Z","shell.execute_reply":"2023-11-08T18:30:10.727369Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"  Flavor Scoops sold Contains chocolate? Smooth or chunky?\n0   Vani         300                                  Smoo\n1   Choc         450                 Yes              Smoo\n2   Cook         275                 Yes              Chun\n3   Mint         315                 Yes              Chun\n4   Fudg         375                 Yes              Chun\n5   Rock         250                 Yes              Chun","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Flavor</th>\n      <th>Scoops sold</th>\n      <th>Contains chocolate?</th>\n      <th>Smooth or chunky?</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Vani</td>\n      <td>300</td>\n      <td></td>\n      <td>Smoo</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Choc</td>\n      <td>450</td>\n      <td>Yes</td>\n      <td>Smoo</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Cook</td>\n      <td>275</td>\n      <td>Yes</td>\n      <td>Chun</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Mint</td>\n      <td>315</td>\n      <td>Yes</td>\n      <td>Chun</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Fudg</td>\n      <td>375</td>\n      <td>Yes</td>\n      <td>Chun</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Rock</td>\n      <td>250</td>\n      <td>Yes</td>\n      <td>Chun</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv('data.csv')\ndisplay(df)","metadata":{"execution":{"iopub.status.busy":"2023-11-08T18:30:10.729631Z","iopub.execute_input":"2023-11-08T18:30:10.730190Z","iopub.status.idle":"2023-11-08T18:30:10.749943Z","shell.execute_reply.started":"2023-11-08T18:30:10.730156Z","shell.execute_reply":"2023-11-08T18:30:10.749027Z"},"trusted":true},"execution_count":52,"outputs":[{"output_type":"display_data","data":{"text/plain":"  Flavor  Scoops sold Contains chocolate? Smooth or chunky?\n0   Vani          300                 NaN              Smoo\n1   Choc          450                 Yes              Smoo\n2   Cook          275                 Yes              Chun\n3   Mint          315                 Yes              Chun\n4   Fudg          375                 Yes              Chun\n5   Rock          250                 Yes              Chun","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Flavor</th>\n      <th>Scoops sold</th>\n      <th>Contains chocolate?</th>\n      <th>Smooth or chunky?</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Vani</td>\n      <td>300</td>\n      <td>NaN</td>\n      <td>Smoo</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Choc</td>\n      <td>450</td>\n      <td>Yes</td>\n      <td>Smoo</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Cook</td>\n      <td>275</td>\n      <td>Yes</td>\n      <td>Chun</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Mint</td>\n      <td>315</td>\n      <td>Yes</td>\n      <td>Chun</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Fudg</td>\n      <td>375</td>\n      <td>Yes</td>\n      <td>Chun</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Rock</td>\n      <td>250</td>\n      <td>Yes</td>\n      <td>Chun</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}